{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk as nl\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noticias_estadao = pd.read_csv('database/noticias_estadao.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def um_termo(termo):\n",
    "    return dict[termo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tem como melhorar esse merge fazendo em tempo O(n+m)\n",
    "def busca_and(termo1, termo2):\n",
    "    ocorr_termo1 = sorted(dict[termo1])\n",
    "    ocorr_termo2 = sorted(dict[termo2])\n",
    "    \n",
    "    ocorrencias = []\n",
    "    \n",
    "    for posting in ocorr_termo1:\n",
    "        if posting in ocorr_termo2:\n",
    "            ocorrencias.append(posting)\n",
    "    \n",
    "    return ocorrencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tem como melhorar isso evitando a transformação para set e depois para sorted (eu acho)\n",
    "def busca_or(termo1, termo2):\n",
    "    ocorr_termo1 = sorted(dict[termo1])\n",
    "    ocorr_termo2 = sorted(dict[termo2])\n",
    "    \n",
    "    return(sorted(set(ocorr_termo1 + ocorr_termo2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check():\n",
    "    result_busca = busca(\"campina\",\"grande\",\"AND\")\n",
    "    print(result_busca)\n",
    "    expected = [1952, 4802, 1987, 6694, 5382, 1770, 2763, 1068, 5870, 2777, 1370, 2779]\n",
    "    \n",
    "    return len(result_busca) == len(expected) and sorted(result_busca) == sorted(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca(termo1, termo2, operador):\n",
    "    if(operador == \"AND\"):\n",
    "        return busca_and(termo1, termo2)\n",
    "    elif(operador == \"OR\"):\n",
    "        return busca_or(termo1, termo2)\n",
    "    else:\n",
    "        raise Exception('Busca não suportada! Buscas suportadas: \"AND\" e \"OR\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca(termo):\n",
    "    return um_termo(termo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tem como melhorar isso de duas formas: Vetorizando e utilizando o índice da notícia ao invés de usar enumerate\n",
    "def produz_tokens(df):\n",
    "    inverted_index = defaultdict(set)\n",
    "    for i, titulos in enumerate(df['titulo']):\n",
    "        tokens = (word.lower() for word in nl.word_tokenize(titulos))\n",
    "        #tokens = nl.word_tokenize(titulos)\n",
    "        for token in tokens:\n",
    "            inverted_index[token].add(i+1)\n",
    "    for i, conteudo in enumerate(df['conteudo']):\n",
    "        tokens = (word.lower() for word in nl.word_tokenize(conteudo))\n",
    "        #tokens = nl.word_tokenize(conteudo)\n",
    "        for token in tokens:\n",
    "            inverted_index[token].add(i+1)\n",
    "    return inverted_index\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = produz_tokens(noticias_estadao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1068, 1370, 1770, 1952, 1987, 2763, 2777, 2779, 4802, 5382, 5870, 6694]\n"
     ]
    }
   ],
   "source": [
    "#result_busca = busca(\"campina\",\"grande\",\"AND\")\n",
    "#expected = [1952, 4802, 1987, 6694, 5382, 1770, 2763, 1068, 5870, 2777, 1370, 2779]\n",
    "\n",
    "assert(sanity_check())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
